# -*- coding: utf-8 -*-
"""Machine_Learning_Assignment_4_700745497.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jWE51EbVAFYe7W5NqWbJ3iHHBr6JV3fP
"""

import pandas as pd
df = pd.read_csv('/content/data.csv')
df

# Show the basic statistical description about the data.
df.describe()

print(df.isnull().values.any()) #checking for null values
df.fillna(df.mean(),inplace=True) #replacing null with mean
print(df.isnull().values.any())

aggre = df.groupby('Duration').agg({'Calories':['min','max','mean','count']})
aggre

df[(df['Calories']>=500) & (df['Calories']<=1000)]

df[(df['Calories']>500) & (df['Pulse']<100)]

# Create a new “df_modified” dataframe that contains all the columns from df except for “Maxpulse”
df_modified = df[['Duration', 'Pulse', 'Calories']]
df_modified

# Delete the “Maxpulse” column from the main df dataframe
df = df.drop('Maxpulse', axis=1)
df

df['Calories'] = df['Calories'].astype('int64')
df.dtypes

df.plot.scatter(x='Duration', y='Calories')

"""Titanic Dataset"""

import matplotlib.pyplot as plt
import seaborn as sns
train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')
titanic = pd.concat([train_df, test_df])
titanic_copy = titanic.copy()
titanic_copy['Survived'] = titanic_copy['Survived'].astype('category').cat.codes
titanic_copy['Embarked'] = titanic_copy['Embarked'].astype('category').cat.codes
titanic_copy['Sex'] = titanic_copy['Sex'].astype('category').cat.codes
corr = titanic_copy['Survived'].corr(titanic_copy['Sex'])
corr

titanic_copy.corr()['Survived']

survived = 'survived'
not_survived = 'not survived'
fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))
men = titanic[titanic['Sex']=='male']
women = titanic[titanic['Sex']=='female']
ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)
ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)
ax.legend()
ax.set_title('Female')
ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)
ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)
ax.legend()
_ = ax.set_title('Male')

# Do you think we should keep this feature?
'''As age is impacting a lot in the survival rate of male when compared to female I consider to keep this feature. '''

sns.lineplot(corr_data)
plt.legend(bbox_to_anchor=(1.3, 1), loc='upper right', borderaxespad=0)

from matplotlib import cm
plt.figure();
corr_data.plot(colormap=cm.cubehelix);

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
titanic_copy = titanic_copy.dropna()
df = titanic_copy.drop(['PassengerId','Name','Ticket','Fare','Cabin'],axis=1)
X = df.drop('Survived', axis=1)
y = df['Survived']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
classifier = GaussianNB()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print('accuracy is',accuracy_score(y_pred,y_test))

"""Glass dataset"""

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
glass = pd.read_csv('/content/glass.csv')
X = glass.iloc[:, :-1].values
y = glass.iloc[:, -1].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
classifier = GaussianNB()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print('accuracy is',accuracy_score(y_pred,y_test),'\n\n')
print(classification_report(y_test, y_pred))

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
classifier_1 = SVC()
classifier_1.fit(X_train, y_train)
y_pred_1 = classifier_1.predict(X_test)
print('accuracy is',accuracy_score(y_pred_1,y_test),'\n\n')
print(classification_report(y_test, y_pred_1))

correlation_data = glass.corr()
sns.heatmap(correlation_data)

sns.scatterplot(correlation_data)
plt.legend(bbox_to_anchor=(1.3, 1), loc='upper right', borderaxespad=0)

